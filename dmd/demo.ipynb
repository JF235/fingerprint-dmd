{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c408fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import dmd\n",
    "import grids as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f57267",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gr.datasets.SD258\n",
    "ds.load(layers=[\"orig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.plot(ds)\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd_pipe = gr.pipelines.dmd()\n",
    "\n",
    "out_dmd = dmd_pipe.run({\"raw_image\": ds[0][\"orig\"]})\n",
    "\n",
    "print(out_dmd.keys())\n",
    "print(out_dmd[\"dmd\"].keys())\n",
    "print(out_dmd[\"fingernet_output\"][\"minutiae\"].shape, out_dmd[\"dmd\"][\"feature\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1338e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle as pkl\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Create template folder\n",
    "template_folder = \"dmd_templates\"\n",
    "os.makedirs(template_folder, exist_ok=True)\n",
    "# Gallery folder\n",
    "gallery_folder = os.path.join(template_folder, \"gallery\")\n",
    "os.makedirs(gallery_folder, exist_ok=True)\n",
    "# Query folder\n",
    "query_folder = os.path.join(template_folder, \"query\")\n",
    "os.makedirs(query_folder, exist_ok=True)\n",
    "\n",
    "latents_template_list = []\n",
    "latents = ds[{\"sid\": 0}]\n",
    "references_template_list = []\n",
    "references = ds[{\"sid\": 1}]\n",
    "\n",
    "noext = lambda f: os.path.splitext(f)[0]\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 64  # Process 64 images at once\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "DEVICE = 'cuda' if USE_GPU else 'cpu'\n",
    "\n",
    "print(f\"ðŸ”§ Device: {DEVICE} | Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Create GPU-accelerated DMD pipeline\n",
    "mntstitch_model_path = \"/fast8TB/jcontreras/work/grfinger/patchgrid/training_template/notebooks/mntstitch/models/resnet34_v2.pt\"\n",
    "dmd_pipe_gpu = gr.pipelines.dmd(mnt_extractor=\"mntstitch\", mntstitch_model_path=mntstitch_model_path, device=DEVICE, use_gpu_patches=USE_GPU, max_batch_size=64)\n",
    "\n",
    "# Helper function to process in batches\n",
    "def process_batch(dataset, folder, batch_size=BATCH_SIZE):\n",
    "    template_list = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Processing batches\"):\n",
    "        # Get batch\n",
    "        batch_end = min(i + batch_size, len(dataset))\n",
    "        batch_items = [dataset[j] for j in range(i, batch_end)]\n",
    "        \n",
    "        # Extract templates in batch\n",
    "        for item in batch_items:\n",
    "            out_dmd = dmd_pipe_gpu.run({\"raw_image\": item[\"orig\"]})\n",
    "            template = out_dmd[\"dmd\"]\n",
    "            template_list.append(template)\n",
    "            \n",
    "            # Save template\n",
    "            template_path = os.path.join(folder, f\"{noext(item.external_id)}.pkl\")\n",
    "            with open(template_path, \"wb\") as f:\n",
    "                pkl.dump(template, f)\n",
    "    \n",
    "    return template_list\n",
    "\n",
    "# Process latents (queries)\n",
    "print(f\"\\nðŸ“¦ Processing {len(latents)} query templates...\")\n",
    "latents_template_list = process_batch(latents, query_folder)\n",
    "\n",
    "# Process references (gallery)\n",
    "print(f\"\\nðŸ“¦ Processing {len(references)} gallery templates...\")\n",
    "references_template_list = process_batch(references, gallery_folder)\n",
    "\n",
    "print(f\"\\nâœ… Done! Extracted {len(latents_template_list)} query and {len(references_template_list)} gallery templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde400e",
   "metadata": {},
   "source": [
    "## ðŸ” Identification (1:N Matching)\n",
    "\n",
    "Load the extracted templates from disk and perform 1:N identification to compute a similarity score matrix between all queries and gallery templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Option 1: Load from memory (if already extracted above)\n",
    "if len(latents_template_list) > 0 and len(references_template_list) > 0:\n",
    "    print(\"Using templates from memory...\")\n",
    "    query_templates = latents_template_list\n",
    "    gallery_templates = references_template_list\n",
    "else:\n",
    "    # Option 2: Load from disk\n",
    "    print(\"Loading templates from disk...\")\n",
    "    \n",
    "    # Load query templates\n",
    "    query_files = sorted(glob(os.path.join(query_folder, \"*.pkl\")))\n",
    "    query_templates = []\n",
    "    for f in query_files:\n",
    "        with open(f, \"rb\") as pkl_file:\n",
    "            query_templates.append(pkl.load(pkl_file))\n",
    "    \n",
    "    # Load gallery templates\n",
    "    gallery_files = sorted(glob(os.path.join(gallery_folder, \"*.pkl\")))\n",
    "    gallery_templates = []\n",
    "    for f in gallery_files:\n",
    "        with open(f, \"rb\") as pkl_file:\n",
    "            gallery_templates.append(pkl.load(pkl_file))\n",
    "\n",
    "print(f\"ðŸ“Š Loaded {len(query_templates)} query templates\")\n",
    "print(f\"ðŸ“Š Loaded {len(gallery_templates)} gallery templates\")\n",
    "\n",
    "# Create DMD matcher\n",
    "matcher = dmd.DmdMatcher()\n",
    "\n",
    "# Perform 1:N identification\n",
    "print(f\"\\nðŸš€ Starting 1:N identification...\")\n",
    "print(f\"   Computing {len(query_templates)} Ã— {len(gallery_templates)} = {len(query_templates) * len(gallery_templates)} comparisons\")\n",
    "\n",
    "IDENTIFICATION_BATCH_SIZE = 256  # Batch size for identification\n",
    "USE_GPU_MATCHING = torch.cuda.is_available()\n",
    "MATCHING_DEVICE = 'cuda' if USE_GPU_MATCHING else 'cpu'\n",
    "\n",
    "print(f\"   Device: {MATCHING_DEVICE} | Batch size: {IDENTIFICATION_BATCH_SIZE}\")\n",
    "\n",
    "# Perform batch identification\n",
    "scores_matrix = matcher.identify(\n",
    "    query_templates, \n",
    "    gallery_templates, \n",
    "    device=MATCHING_DEVICE,\n",
    "    batch_size=IDENTIFICATION_BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Identification complete!\")\n",
    "print(f\"   Score matrix shape: {scores_matrix.shape}\")\n",
    "print(f\"   Score range: [{scores_matrix.min():.4f}, {scores_matrix.max():.4f}]\")\n",
    "\n",
    "# Create ground truth matrix (assuming same subject IDs)\n",
    "# For SD258: subject IDs are the same for matching pairs\n",
    "num_queries = len(query_templates)\n",
    "num_gallery = len(gallery_templates)\n",
    "\n",
    "# Assuming query subject 0 matches gallery subject 0, etc.\n",
    "# Adjust this based on your dataset structure\n",
    "target_matrix = np.zeros((num_queries, num_gallery), dtype=bool)\n",
    "for i in range(min(num_queries, num_gallery)):\n",
    "    target_matrix[i, i] = True  # Diagonal = genuine matches\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Ground truth matrix shape: {target_matrix.shape}\")\n",
    "print(f\"   Genuine pairs: {target_matrix.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489598a",
   "metadata": {},
   "source": [
    "## ðŸ“Š CMC Curve (Cumulative Match Characteristic)\n",
    "\n",
    "Compute and plot the CMC curve to evaluate identification performance at different ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e75e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute CMC curve\n",
    "def compute_cmc(score_matrix, target_matrix, max_rank=20):\n",
    "    \"\"\"\n",
    "    Compute Cumulative Match Characteristic (CMC) curve.\n",
    "    \n",
    "    Args:\n",
    "        score_matrix: Score matrix [num_queries, num_gallery]\n",
    "        target_matrix: Ground truth matrix [num_queries, num_gallery]\n",
    "        max_rank: Maximum rank to compute (default: 20)\n",
    "        \n",
    "    Returns:\n",
    "        cmc: CMC values for ranks 1 to max_rank\n",
    "    \"\"\"\n",
    "    num_queries = score_matrix.shape[0]\n",
    "    \n",
    "    # Get sorted indices (highest scores first)\n",
    "    sorted_indices = np.argsort(score_matrix, axis=1)[:, ::-1]\n",
    "    \n",
    "    # Initialize CMC\n",
    "    cmc = np.zeros(max_rank)\n",
    "    \n",
    "    # For each rank\n",
    "    for rank in range(max_rank):\n",
    "        # Get top-(rank+1) predictions\n",
    "        top_k_indices = sorted_indices[:, :rank+1]\n",
    "        \n",
    "        # Check if any of top-k matches is genuine\n",
    "        correct = 0\n",
    "        for q_idx in range(num_queries):\n",
    "            top_k = top_k_indices[q_idx]\n",
    "            if np.any(target_matrix[q_idx, top_k]):\n",
    "                correct += 1\n",
    "        \n",
    "        cmc[rank] = correct / num_queries\n",
    "    \n",
    "    return cmc\n",
    "\n",
    "# Compute CMC\n",
    "print(\"Computing CMC curve...\")\n",
    "cmc = compute_cmc(scores_matrix, target_matrix, max_rank=257)\n",
    "\n",
    "# Print key metrics\n",
    "print(f\"\\nðŸ“ˆ Identification Results:\")\n",
    "print(f\"   Rank-1:  {cmc[0]*100:.2f}%\")\n",
    "print(f\"   Rank-5:  {cmc[4]*100:.2f}%\")\n",
    "print(f\"   Rank-10: {cmc[9]*100:.2f}%\")\n",
    "print(f\"   Rank-20: {cmc[19]*100:.2f}%\")\n",
    "print(f\"   Rank-50: {cmc[49]*100:.2f}%\")\n",
    "\n",
    "# Plot CMC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "ranks = np.arange(1, len(cmc) + 1)\n",
    "plt.plot(ranks, cmc * 100, 'b-', linewidth=2, markersize=6, label='DMD++')\n",
    "plt.xlabel('Rank', fontsize=12)\n",
    "plt.ylabel('Identification Rate (%)', fontsize=12)\n",
    "plt.title('Cumulative Match Characteristic (CMC) Curve', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xlim([1, len(cmc)])\n",
    "plt.ylim([0, 105])\n",
    "plt.xticks(np.arange(1, len(cmc) + 1, 10))\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "# Add value annotations for key ranks\n",
    "for rank_idx in [0, 4, 9, 19, 49, 99, 256]:  # Rank 1, 5, 10, 20\n",
    "    if rank_idx < len(cmc):\n",
    "        plt.annotate(f'{cmc[rank_idx]*100:.1f}%', \n",
    "                    xy=(rank_idx + 1, cmc[rank_idx] * 100),\n",
    "                    xytext=(10, -10), textcoords='offset points',\n",
    "                    fontsize=9, color='darkblue',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='darkblue'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… CMC curve plotted!\") # 86.4 at rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3a3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
