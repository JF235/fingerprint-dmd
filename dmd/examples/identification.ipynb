{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMD++ Fingerprint Identification with Background Gallery\n",
    "\n",
    "This notebook performs 1:N fingerprint identification using DMD++ templates.\n",
    "\n",
    "**Experiment Setup:**\n",
    "- **Query Set:** 258 latent fingerprints from SD258 dataset (sid=0)\n",
    "- **Gallery Set:** 258 reference fingerprints from SD258 (sid=1) [+ background from TS1K (sid=0), optional]\n",
    "- **Task:** Identify each query in the large gallery\n",
    "\n",
    "**Checkpoints:** Templates and identification results are saved to disk to avoid recomputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Set all experiment parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== EXPERIMENT CONFIGURATION ==========\n",
    "\n",
    "# Number of background samples to use from TS1K (set to None to use all available)\n",
    "NUM_BACKGROUND_SAMPLES = 0  # Use None for all, or set a number like 1000, 5000, 10000\n",
    "\n",
    "# Template extraction settings\n",
    "BATCH_SIZE = 64\n",
    "USE_GPU = True\n",
    "DEVICE = 'cuda:4' if USE_GPU else 'cpu'\n",
    "\n",
    "# Identification settings\n",
    "IDENTIFICATION_BATCH_SIZE = 256\n",
    "\n",
    "# Results folder\n",
    "RESULTS_FOLDER = \"dmd_sd27\"\n",
    "\n",
    "# Error visualization\n",
    "MAX_DISPLAY_ERR = 10\n",
    "\n",
    "# CMC settings\n",
    "MAX_CMC_RANK = 258  # Maximum rank to compute for CMC curve\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Background samples: {NUM_BACKGROUND_SAMPLES if NUM_BACKGROUND_SAMPLES else 'All available'}\")\n",
    "print(f\"  Results folder: {RESULTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "import dmd\n",
    "import grids as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder structure\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Query folder (SD258 latents)\n",
    "query_folder = os.path.join(RESULTS_FOLDER, \"query\")\n",
    "os.makedirs(query_folder, exist_ok=True)\n",
    "\n",
    "# Gallery folders\n",
    "gallery_sd258_folder = os.path.join(RESULTS_FOLDER, \"gallery_sd258\")\n",
    "os.makedirs(gallery_sd258_folder, exist_ok=True)\n",
    "\n",
    "gallery_ts1k_folder = os.path.join(RESULTS_FOLDER, \"gallery_ts1k\")\n",
    "os.makedirs(gallery_ts1k_folder, exist_ok=True)\n",
    "\n",
    "print(f\"Folder structure created:\")\n",
    "print(f\"  Query: {query_folder}\")\n",
    "print(f\"  Gallery SD258: {gallery_sd258_folder}\")\n",
    "print(f\"  Gallery TS1K: {gallery_ts1k_folder}\")\n",
    "\n",
    "# Helper function\n",
    "noext = lambda f: os.path.splitext(f)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SD258 dataset\n",
    "print(\"Loading SD258 dataset...\")\n",
    "ds_sd258 = gr.datasets.SD258\n",
    "ds_sd258.load(layers=[\"orig\"])\n",
    "\n",
    "# Query set: SD258 latents (sid=0)\n",
    "queries = ds_sd258[{\"sid\": 0}]\n",
    "print(f\"  Queries (SD258 sid=0): {len(queries)} samples\")\n",
    "\n",
    "# Gallery SD258: references (sid=1)\n",
    "gallery_sd258 = ds_sd258[{\"sid\": 1}]\n",
    "print(f\"  Gallery SD258 (sid=1): {len(gallery_sd258)} samples\")\n",
    "\n",
    "# Load TS1K dataset for background gallery only if needed\n",
    "if NUM_BACKGROUND_SAMPLES is None or NUM_BACKGROUND_SAMPLES > 0:\n",
    "    print(\"\\nLoading TS1K dataset for background...\")\n",
    "    ds_ts1k = gr.datasets.TS1K\n",
    "    ds_ts1k.log()\n",
    "    ds_ts1k.load(layers=[\"orig\"])\n",
    "\n",
    "    # Background gallery: TS1K (sid=0 only, to avoid duplicates)\n",
    "    gallery_ts1k_full = ds_ts1k[{\"sid\": 0}]\n",
    "    print(f\"  Total TS1K samples available (sid=0): {len(gallery_ts1k_full)}\")\n",
    "\n",
    "    # Apply limit if specified\n",
    "    if NUM_BACKGROUND_SAMPLES is not None:\n",
    "        gallery_ts1k = [gallery_ts1k_full[i] for i in range(min(NUM_BACKGROUND_SAMPLES, len(gallery_ts1k_full)))]\n",
    "        print(f\"  Using limited TS1K samples: {len(gallery_ts1k)}\")\n",
    "    else:\n",
    "        gallery_ts1k = gallery_ts1k_full\n",
    "        print(f\"  Using all available TS1K samples: {len(gallery_ts1k)}\")\n",
    "else:\n",
    "    print(\"\\nSkipping TS1K dataset (NUM_BACKGROUND_SAMPLES = 0)\")\n",
    "    gallery_ts1k = []\n",
    "\n",
    "print(f\"\\nFinal configuration:\")\n",
    "print(f\"  Queries: {len(queries)}\")\n",
    "print(f\"  Gallery (SD258): {len(gallery_sd258)}\")\n",
    "print(f\"  Gallery (TS1K): {len(gallery_ts1k)}\")\n",
    "print(f\"  Total Gallery: {len(gallery_sd258) + len(gallery_ts1k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Template Extraction\n",
    "\n",
    "Extract DMD++ templates for all fingerprints. Templates are saved to disk to avoid recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if templates already exist\n",
    "query_files = sorted(glob(os.path.join(query_folder, \"*.pkl\")))\n",
    "gallery_sd258_files = sorted(glob(os.path.join(gallery_sd258_folder, \"*.pkl\")))\n",
    "gallery_ts1k_files = sorted(glob(os.path.join(gallery_ts1k_folder, \"*.pkl\")))\n",
    "\n",
    "# Determine expected number of TS1K templates based on NUM_BACKGROUND_SAMPLES\n",
    "if NUM_BACKGROUND_SAMPLES is None or NUM_BACKGROUND_SAMPLES > 0:\n",
    "    expected_ts1k_templates = len(gallery_ts1k)\n",
    "else:\n",
    "    expected_ts1k_templates = 0\n",
    "\n",
    "templates_exist = (\n",
    "    len(query_files) == len(queries) and\n",
    "    len(gallery_sd258_files) == len(gallery_sd258) and\n",
    "    len(gallery_ts1k_files) >= expected_ts1k_templates\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if templates_exist:\n",
    "    print(\"âœ… Templates already extracted!\")\n",
    "    print(f\"   Queries: {len(query_files)} files\")\n",
    "    print(f\"   Gallery SD258: {len(gallery_sd258_files)} files\")\n",
    "    print(f\"   Gallery TS1K: {len(gallery_ts1k_files)} files (need {expected_ts1k_templates})\")\n",
    "    print(\"\\n   Skipping extraction. Delete template folders to re-extract.\")\n",
    "else:\n",
    "    print(\"ðŸ”§ Templates not found or incomplete. Starting extraction...\\n\")\n",
    "    \n",
    "    # Helper function to move template to CPU\n",
    "    def move_template_to_cpu(template):\n",
    "        \"\"\"Move all tensors in a template to CPU for storage.\"\"\"\n",
    "        template_cpu = {}\n",
    "        for key, value in template.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                template_cpu[key] = value.cpu()\n",
    "            else:\n",
    "                template_cpu[key] = value\n",
    "        return template_cpu\n",
    "    \n",
    "    # Create DMD pipeline\n",
    "    mntstitch_model_path = \"/fast8TB/jcontreras/work/grfinger/patchgrid/training_template_stitch/notebooks/mntstitch/models/resnet34_v2.pt\"\n",
    "\n",
    "    # Helper function to extract templates\n",
    "    def extract_templates(dataset, folder, desc):\n",
    "        \"\"\"Extract DMD templates for a dataset and save to folder.\"\"\"\n",
    "        template_list = []\n",
    "        \n",
    "        for item in tqdm(dataset, desc=desc):\n",
    "            # Extract template\n",
    "            out_dmd = dmd_pipe.run({\"raw_image\": item[\"orig\"]})\n",
    "            template = out_dmd[\"dmd\"]\n",
    "            \n",
    "            # Move to CPU before saving (for portability)\n",
    "            template_cpu = move_template_to_cpu(template)\n",
    "            template_list.append(template)\n",
    "            \n",
    "            # Save to disk (CPU version for portability)\n",
    "            template_path = os.path.join(folder, f\"{noext(item.external_id)}.pkl\")\n",
    "            with open(template_path, \"wb\") as f:\n",
    "                pkl.dump(template_cpu, f)\n",
    "        \n",
    "        return template_list\n",
    "    \n",
    "    # Query extraction pipeline\n",
    "    dmd_pipe = gr.pipelines.dmd(\n",
    "        mnt_extractor=\"mntstitch\",\n",
    "        mntstitch_model_path=mntstitch_model_path,\n",
    "        device=DEVICE,\n",
    "        use_gpu_patches=USE_GPU,\n",
    "        max_batch_size=BATCH_SIZE,\n",
    "        mntstitch_kwargs={\"qthreshold\": 0.15}\n",
    "    )\n",
    "\n",
    "    # Extract query templates\n",
    "    print(f\"ðŸ“¦ Extracting {len(queries)} query templates...\")\n",
    "    query_templates = extract_templates(queries, query_folder, \"Queries\")\n",
    "    \n",
    "    # Gallery extraction pipeline\n",
    "    dmd_pipe = gr.pipelines.dmd(\n",
    "        mnt_extractor=\"mntstitch\",\n",
    "        mntstitch_model_path=mntstitch_model_path,\n",
    "        device=DEVICE,\n",
    "        use_gpu_patches=USE_GPU,\n",
    "        max_batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Extract SD258 gallery templates\n",
    "    print(f\"\\nðŸ“¦ Extracting {len(gallery_sd258)} SD258 gallery templates...\")\n",
    "    gallery_sd258_templates = extract_templates(gallery_sd258, gallery_sd258_folder, \"Gallery SD258\")\n",
    "    \n",
    "    # Extract TS1K gallery templates only if needed\n",
    "    if len(gallery_ts1k) > 0:\n",
    "        print(f\"\\n Extracting {len(gallery_ts1k)} TS1K gallery templates...\")\n",
    "        gallery_ts1k_templates = extract_templates(gallery_ts1k, gallery_ts1k_folder, \"Gallery TS1K\")\n",
    "    else:\n",
    "        print(f\"\\n Skipping TS1K template extraction (NUM_BACKGROUND_SAMPLES = 0)\")\n",
    "        gallery_ts1k_templates = []\n",
    "    \n",
    "    print(f\"\\nâœ… Template extraction complete!\")\n",
    "    print(f\"   Total templates: {len(query_templates) + len(gallery_sd258_templates) + len(gallery_ts1k_templates)}\")\n",
    "    print(f\"   Templates saved to CPU for portability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Templates from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading templates from disk...\\n\")\n",
    "\n",
    "def move_template_to_device(template, device):\n",
    "    \"\"\"Move all tensors in a template to the specified device.\"\"\"\n",
    "    template_moved = {}\n",
    "    for key, value in template.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            template_moved[key] = value.to(device)\n",
    "        else:\n",
    "            template_moved[key] = value\n",
    "    return template_moved\n",
    "\n",
    "# Load query templates\n",
    "query_files = sorted(glob(os.path.join(query_folder, \"*.pkl\")))\n",
    "query_templates = []\n",
    "for f in tqdm(query_files, desc=\"Loading queries\"):\n",
    "    with open(f, \"rb\") as pkl_file:\n",
    "        template = pkl.load(pkl_file)\n",
    "        # Move template to configured device\n",
    "        template = move_template_to_device(template, DEVICE)\n",
    "        query_templates.append(template)\n",
    "\n",
    "# Load SD258 gallery templates\n",
    "gallery_sd258_files = sorted(glob(os.path.join(gallery_sd258_folder, \"*.pkl\")))\n",
    "gallery_sd258_templates = []\n",
    "for f in tqdm(gallery_sd258_files, desc=\"Loading SD258 gallery\"):\n",
    "    with open(f, \"rb\") as pkl_file:\n",
    "        template = pkl.load(pkl_file)\n",
    "        # Move template to configured device\n",
    "        template = move_template_to_device(template, DEVICE)\n",
    "        gallery_sd258_templates.append(template)\n",
    "\n",
    "# Load TS1K gallery templates only if needed\n",
    "if NUM_BACKGROUND_SAMPLES is None or NUM_BACKGROUND_SAMPLES > 0:\n",
    "    gallery_ts1k_files = sorted(glob(os.path.join(gallery_ts1k_folder, \"*.pkl\")))\n",
    "    gallery_ts1k_files = gallery_ts1k_files[:NUM_BACKGROUND_SAMPLES if NUM_BACKGROUND_SAMPLES else None]\n",
    "    gallery_ts1k_templates = []\n",
    "    for f in tqdm(gallery_ts1k_files, desc=\"Loading TS1K gallery\"):\n",
    "        with open(f, \"rb\") as pkl_file:\n",
    "            template = pkl.load(pkl_file)\n",
    "            # Move template to configured device\n",
    "            template = move_template_to_device(template, DEVICE)\n",
    "            gallery_ts1k_templates.append(template)\n",
    "else:\n",
    "    print(\"Skipping TS1K template loading (NUM_BACKGROUND_SAMPLES = 0)\")\n",
    "    gallery_ts1k_files = []\n",
    "    gallery_ts1k_templates = []\n",
    "\n",
    "# Combine gallery templates (SD258 first, then TS1K)\n",
    "gallery_templates = gallery_sd258_templates + gallery_ts1k_templates\n",
    "\n",
    "print(f\"\\nâœ… Templates loaded and moved to {DEVICE}:\")\n",
    "print(f\"   Queries: {len(query_templates)}\")\n",
    "print(f\"   Gallery SD258: {len(gallery_sd258_templates)}\")\n",
    "print(f\"   Gallery TS1K: {len(gallery_ts1k_templates)}\")\n",
    "print(f\"   Total Gallery: {len(gallery_templates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Template Quality Check\n",
    "\n",
    "Identify and remove templates with no minutiae (which cause matching errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def check_template_quality(templates, names, filter_low_minutiae=True):\n",
    "    \"\"\"\n",
    "    Check template quality and identify problematic templates.\n",
    "    \n",
    "    Args:\n",
    "        filter_low_minutiae: If True, filter templates with < 4 minutiae (for gallery only)\n",
    "    \n",
    "    Returns:\n",
    "        bad_indices: List of indices with problems\n",
    "        reasons: Dict mapping index to reason for failure\n",
    "    \"\"\"\n",
    "    bad_indices = []\n",
    "    reasons = {}\n",
    "    \n",
    "    for i, template in enumerate(templates):\n",
    "        problems = []\n",
    "        \n",
    "        # Check minutiae\n",
    "        mnt = template['mnt']\n",
    "        num_mnt = 0\n",
    "        \n",
    "        if isinstance(mnt, torch.Tensor):\n",
    "            if mnt.shape[0] == 0 or (len(mnt.shape) > 1 and mnt.shape[1] == 0):\n",
    "                problems.append(\"empty_mnt_shape\")\n",
    "            else:\n",
    "                # Count valid minutiae (non-NaN in first column)\n",
    "                if mnt.numel() > 0:\n",
    "                    # Handle different shapes: (N, 3) or (1, N, 3)\n",
    "                    if len(mnt.shape) == 3:\n",
    "                        num_mnt = torch.sum(~torch.isnan(mnt[0, :, 0])).item()\n",
    "                    else:\n",
    "                        num_mnt = torch.sum(~torch.isnan(mnt[:, 0])).item()\n",
    "                \n",
    "                if num_mnt == 0:\n",
    "                    problems.append(\"zero_minutiae\")\n",
    "                elif filter_low_minutiae and num_mnt < 4:\n",
    "                    problems.append(f\"too_few_minutiae({num_mnt})\")\n",
    "        else:\n",
    "            # NumPy array\n",
    "            if mnt.shape[0] == 0 or (len(mnt.shape) > 1 and mnt.shape[1] == 0):\n",
    "                problems.append(\"empty_mnt_shape\")\n",
    "            else:\n",
    "                if mnt.size > 0:\n",
    "                    # Handle different shapes\n",
    "                    if len(mnt.shape) == 3:\n",
    "                        num_mnt = np.sum(~np.isnan(mnt[0, :, 0]))\n",
    "                    else:\n",
    "                        num_mnt = np.sum(~np.isnan(mnt[:, 0]))\n",
    "                \n",
    "                if num_mnt == 0:\n",
    "                    problems.append(\"zero_minutiae\")\n",
    "                elif filter_low_minutiae and num_mnt < 4:\n",
    "                    problems.append(f\"too_few_minutiae({num_mnt})\")\n",
    "        \n",
    "        # Check features (DMD uses 'feature' key, not 'desc')\n",
    "        feat = template['feature']\n",
    "        if isinstance(feat, torch.Tensor):\n",
    "            if feat.numel() == 0:\n",
    "                problems.append(\"empty_feature\")\n",
    "            elif torch.isnan(feat).any():\n",
    "                problems.append(\"nan_features\")\n",
    "            elif torch.isinf(feat).any():\n",
    "                problems.append(\"inf_features\")\n",
    "        else:\n",
    "            # NumPy array\n",
    "            if feat.size == 0:\n",
    "                problems.append(\"empty_feature\")\n",
    "            elif np.isnan(feat).any():\n",
    "                problems.append(\"nan_features\")\n",
    "            elif np.isinf(feat).any():\n",
    "                problems.append(\"inf_features\")\n",
    "        \n",
    "        if problems:\n",
    "            bad_indices.append(i)\n",
    "            reasons[i] = problems\n",
    "    \n",
    "    return bad_indices, reasons\n",
    "\n",
    "# Check quality of all template sets\n",
    "print(\"ðŸ” Checking template quality...\\n\")\n",
    "\n",
    "# For queries (latents): only check for reporting, DO NOT filter\n",
    "bad_queries, reasons_q = check_template_quality(query_templates, \"Queries\", filter_low_minutiae=False)\n",
    "\n",
    "# For gallery (references): check everything including low minutiae count\n",
    "bad_sd258, reasons_sd258 = check_template_quality(gallery_sd258_templates, \"Gallery SD258\", filter_low_minutiae=True)\n",
    "bad_ts1k, reasons_ts1k = check_template_quality(gallery_ts1k_templates, \"Gallery TS1K\", filter_low_minutiae=True)\n",
    "\n",
    "print(f\"Problematic templates found:\")\n",
    "print(f\"  Queries (latents): {len(bad_queries)} / {len(query_templates)} [reporting only, NOT filtered]\")\n",
    "if bad_queries and len(bad_queries) <= 10:\n",
    "    for idx in bad_queries:\n",
    "        print(f\"    [{idx}] {reasons_q[idx]}\")\n",
    "\n",
    "print(f\"  Gallery SD258 (references): {len(bad_sd258)} / {len(gallery_sd258_templates)} [will be filtered]\")\n",
    "if bad_sd258 and len(bad_sd258) <= 10:\n",
    "    for idx in bad_sd258:\n",
    "        print(f\"    [{idx}] {reasons_sd258[idx]}\")\n",
    "\n",
    "print(f\"  Gallery TS1K (references): {len(bad_ts1k)} / {len(gallery_ts1k_templates)} [will be filtered]\")\n",
    "if bad_ts1k:\n",
    "    if len(bad_ts1k) <= 20:\n",
    "        for idx in bad_ts1k:\n",
    "            ts1k_id = noext(os.path.basename(gallery_ts1k_files[idx]))\n",
    "            print(f\"    [{idx}] {ts1k_id}: {reasons_ts1k[idx]}\")\n",
    "    else:\n",
    "        print(f\"    Too many bad templates ({len(bad_ts1k)}), showing first 20:\")\n",
    "        for idx in bad_ts1k[:20]:\n",
    "            ts1k_id = noext(os.path.basename(gallery_ts1k_files[idx]))\n",
    "            print(f\"    [{idx}] {ts1k_id}: {reasons_ts1k[idx]}\")\n",
    "        print(f\"    ... and {len(bad_ts1k) - 20} more\")\n",
    "\n",
    "# Filter ONLY gallery templates, NEVER queries\n",
    "if len(bad_sd258) > 0 or len(bad_ts1k) > 0:\n",
    "    print(f\"\\nâš ï¸  Found {len(bad_sd258) + len(bad_ts1k)} problematic gallery templates!\")\n",
    "    print(f\"   Filtering them out...\\n\")\n",
    "    \n",
    "    # NEVER filter queries - keep all of them\n",
    "    query_templates_filtered = query_templates\n",
    "    queries_filtered = queries\n",
    "    query_ids_filtered = [noext(os.path.basename(f)) for f in query_files]\n",
    "    \n",
    "    # Filter SD258 gallery\n",
    "    if len(bad_sd258) > 0:\n",
    "        gallery_sd258_templates_filtered = [t for i, t in enumerate(gallery_sd258_templates) if i not in bad_sd258]\n",
    "        gallery_sd258_filtered = [g for i, g in enumerate(gallery_sd258) if i not in bad_sd258]\n",
    "        gallery_sd258_ids_filtered = [noext(os.path.basename(gallery_sd258_files[i])) for i in range(len(gallery_sd258_files)) if i not in bad_sd258]\n",
    "        print(f\"   Removed {len(bad_sd258)} SD258 gallery. Remaining: {len(gallery_sd258_templates_filtered)}\")\n",
    "    else:\n",
    "        gallery_sd258_templates_filtered = gallery_sd258_templates\n",
    "        gallery_sd258_filtered = gallery_sd258\n",
    "        gallery_sd258_ids_filtered = [noext(os.path.basename(f)) for f in gallery_sd258_files]\n",
    "    \n",
    "    # Filter TS1K gallery\n",
    "    if len(bad_ts1k) > 0:\n",
    "        gallery_ts1k_templates_filtered = [t for i, t in enumerate(gallery_ts1k_templates) if i not in bad_ts1k]\n",
    "        gallery_ts1k_filtered = [g for i, g in enumerate(gallery_ts1k) if i not in bad_ts1k]\n",
    "        gallery_ts1k_ids_filtered = [noext(os.path.basename(gallery_ts1k_files[i])) for i in range(len(gallery_ts1k_files)) if i not in bad_ts1k]\n",
    "        print(f\"   Removed {len(bad_ts1k)} TS1K gallery. Remaining: {len(gallery_ts1k_templates_filtered)}\")\n",
    "    else:\n",
    "        gallery_ts1k_templates_filtered = gallery_ts1k_templates\n",
    "        gallery_ts1k_filtered = gallery_ts1k\n",
    "        gallery_ts1k_ids_filtered = [noext(os.path.basename(f)) for f in gallery_ts1k_files]\n",
    "    \n",
    "    # Update references\n",
    "    query_templates = query_templates_filtered\n",
    "    queries = queries_filtered\n",
    "    query_ids = query_ids_filtered\n",
    "    \n",
    "    gallery_sd258_templates = gallery_sd258_templates_filtered\n",
    "    gallery_sd258 = gallery_sd258_filtered\n",
    "    gallery_sd258_ids = gallery_sd258_ids_filtered\n",
    "    \n",
    "    gallery_ts1k_templates = gallery_ts1k_templates_filtered\n",
    "    gallery_ts1k = gallery_ts1k_filtered\n",
    "    gallery_ts1k_ids = gallery_ts1k_ids_filtered\n",
    "    \n",
    "    # Recombine gallery\n",
    "    gallery_templates = gallery_sd258_templates + gallery_ts1k_templates\n",
    "    gallery_ids = gallery_sd258_ids + gallery_ts1k_ids\n",
    "    \n",
    "    print(f\"\\nâœ… Filtered templates:\")\n",
    "    print(f\"   Queries: {len(query_templates)} (no filtering applied)\")\n",
    "    print(f\"   Gallery SD258: {len(gallery_sd258_templates)}\")\n",
    "    print(f\"   Gallery TS1K: {len(gallery_ts1k_templates)}\")\n",
    "    print(f\"   Total Gallery: {len(gallery_templates)}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… All gallery templates have valid quality. No filtering needed.\")\n",
    "    \n",
    "    # Still need to create ID lists for ground truth mapping\n",
    "    query_ids = [noext(os.path.basename(f)) for f in query_files]\n",
    "    gallery_sd258_ids = [noext(os.path.basename(f)) for f in gallery_sd258_files]\n",
    "    gallery_ts1k_ids = [noext(os.path.basename(f)) for f in gallery_ts1k_files]\n",
    "    gallery_ids = gallery_sd258_ids + gallery_ts1k_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identification (1:N Matching)\n",
    "\n",
    "Compute similarity scores between all queries and gallery templates.\n",
    "Results are saved to avoid recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for identification results\n",
    "identification_results_path = os.path.join(RESULTS_FOLDER, \"identification_results.pkl\")\n",
    "\n",
    "# Check if results already exist\n",
    "if os.path.exists(identification_results_path):\n",
    "    print(\"ðŸ“‚ Loading identification results from disk...\")\n",
    "    with open(identification_results_path, \"rb\") as f:\n",
    "        results = pkl.load(f)\n",
    "        scores_matrix = results[\"scores_matrix\"]\n",
    "    \n",
    "    print(f\"âœ… Loaded scores matrix!\")\n",
    "    print(f\"   Score matrix shape: {scores_matrix.shape}\")\n",
    "    print(f\"   Score range: [{np.nanmin(scores_matrix):.4f}, {np.nanmax(scores_matrix):.4f}]\")\n",
    "    \n",
    "    # ALWAYS rebuild ground truth with current IDs (in case filtering changed)\n",
    "    print(f\"\\nðŸ“‹ Rebuilding ground truth matrix with current IDs...\")\n",
    "    \n",
    "    num_queries = len(query_templates)\n",
    "    num_gallery = len(gallery_templates)\n",
    "    num_sd258_gallery = len(gallery_sd258_templates)\n",
    "    \n",
    "    target_matrix = np.zeros((num_queries, num_gallery), dtype=bool)\n",
    "    \n",
    "    # For each query, find its matching gallery image in SD258 part\n",
    "    matches_found = 0\n",
    "    matches_not_found = []\n",
    "    \n",
    "    for q_idx, q_id in enumerate(query_ids):\n",
    "        # Extract prefix (e.g., \"sd258_000_11-00_latent_bad\" -> \"sd258_000_11\")\n",
    "        q_prefix = \"_\".join(q_id.split(\"_\")[:2])\n",
    "        \n",
    "        # Find matching gallery ID in SD258 part only\n",
    "        found = False\n",
    "        for g_idx, g_id in enumerate(gallery_sd258_ids):\n",
    "            g_prefix = \"_\".join(g_id.split(\"_\")[:2])\n",
    "            if q_prefix == g_prefix:\n",
    "                # This is the correct match\n",
    "                target_matrix[q_idx, g_idx] = True\n",
    "                matches_found += 1\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            matches_not_found.append((q_idx, q_id))\n",
    "    \n",
    "    print(f\"   Matches found: {matches_found} / {num_queries}\")\n",
    "    \n",
    "    if matches_not_found:\n",
    "        print(f\"   âš ï¸  {len(matches_not_found)} queries without matches:\")\n",
    "        for q_idx, q_id in matches_not_found[:10]:\n",
    "            print(f\"      [{q_idx}] {q_id}\")\n",
    "        if len(matches_not_found) > 10:\n",
    "            print(f\"      ... and {len(matches_not_found) - 10} more\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Ground truth matrix:\")\n",
    "    print(f\"   Shape: {target_matrix.shape}\")\n",
    "    print(f\"   Genuine pairs (SD258): {target_matrix.sum()}\")\n",
    "    print(f\"   Impostor pairs (TS1K): {num_queries * len(gallery_ts1k_templates)}\")\n",
    "    \n",
    "    # Save updated results\n",
    "    print(f\"\\nðŸ’¾ Saving updated results...\")\n",
    "    results = {\n",
    "        \"scores_matrix\": scores_matrix,\n",
    "        \"target_matrix\": target_matrix,\n",
    "        \"query_ids\": query_ids,\n",
    "        \"gallery_ids\": gallery_ids,\n",
    "        \"metadata\": {\n",
    "            \"num_queries\": num_queries,\n",
    "            \"num_gallery_sd258\": num_sd258_gallery,\n",
    "            \"num_gallery_ts1k\": len(gallery_ts1k_templates),\n",
    "            \"num_gallery_total\": num_gallery,\n",
    "            \"matches_found\": matches_found\n",
    "        }\n",
    "    }\n",
    "    with open(identification_results_path, \"wb\") as f:\n",
    "        pkl.dump(results, f)\n",
    "    print(f\"   Saved to: {identification_results_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"ðŸš€ Starting 1:N identification...\")\n",
    "    print(f\"   Computing {len(query_templates)} Ã— {len(gallery_templates)} = {len(query_templates) * len(gallery_templates):,} comparisons\")\n",
    "    print(f\"   Device: {DEVICE}\")\n",
    "    print(f\"   Batch size: {IDENTIFICATION_BATCH_SIZE}\")\n",
    "    \n",
    "    # Create matcher\n",
    "    matcher = dmd.DmdMatcher()\n",
    "    \n",
    "    # Perform identification\n",
    "    scores_matrix = matcher.identify(\n",
    "        query_templates,\n",
    "        gallery_templates,\n",
    "        device=DEVICE,\n",
    "        batch_size=IDENTIFICATION_BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Identification complete!\")\n",
    "    print(f\"   Score matrix shape: {scores_matrix.shape}\")\n",
    "    print(f\"   Score range: [{np.nanmin(scores_matrix):.4f}, {np.nanmax(scores_matrix):.4f}]\")\n",
    "    \n",
    "    # Create ground truth matrix by matching IDs\n",
    "    # Query IDs are like \"sd258_000_11-00_latent_bad\", Gallery IDs are like \"sd258_000_11-01_template_bad\"\n",
    "    # They match if the prefix (first 2 parts) is the same\n",
    "    num_queries = len(query_templates)\n",
    "    num_gallery = len(gallery_templates)\n",
    "    num_sd258_gallery = len(gallery_sd258_templates)\n",
    "    \n",
    "    target_matrix = np.zeros((num_queries, num_gallery), dtype=bool)\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Building ground truth matrix by matching IDs...\")\n",
    "    \n",
    "    # For each query, find its matching gallery image in SD258 part\n",
    "    matches_found = 0\n",
    "    matches_not_found = []\n",
    "    \n",
    "    for q_idx, q_id in enumerate(query_ids):\n",
    "        # Extract prefix (e.g., \"sd258_000_11-00_latent_bad\" -> \"sd258_000_11\")\n",
    "        q_prefix = \"_\".join(q_id.split(\"_\")[:2])\n",
    "        \n",
    "        # Find matching gallery ID in SD258 part only\n",
    "        found = False\n",
    "        for g_idx, g_id in enumerate(gallery_sd258_ids):\n",
    "            g_prefix = \"_\".join(g_id.split(\"_\")[:2])\n",
    "            if q_prefix == g_prefix:\n",
    "                # This is the correct match\n",
    "                target_matrix[q_idx, g_idx] = True\n",
    "                matches_found += 1\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            matches_not_found.append((q_idx, q_id))\n",
    "    \n",
    "    print(f\"   Matches found: {matches_found} / {num_queries}\")\n",
    "    \n",
    "    if matches_not_found:\n",
    "        print(f\"   âš ï¸  {len(matches_not_found)} queries without matches:\")\n",
    "        for q_idx, q_id in matches_not_found[:10]:\n",
    "            print(f\"      [{q_idx}] {q_id}\")\n",
    "        if len(matches_not_found) > 10:\n",
    "            print(f\"      ... and {len(matches_not_found) - 10} more\")\n",
    "    \n",
    "    # TS1K entries are all impostors (already False)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Ground truth matrix:\")\n",
    "    print(f\"   Shape: {target_matrix.shape}\")\n",
    "    print(f\"   Genuine pairs (SD258): {target_matrix.sum()}\")\n",
    "    print(f\"   Impostor pairs (TS1K): {num_queries * len(gallery_ts1k_templates)}\")\n",
    "    \n",
    "    # Save results\n",
    "    print(f\"\\nðŸ’¾ Saving identification results...\")\n",
    "    results = {\n",
    "        \"scores_matrix\": scores_matrix,\n",
    "        \"target_matrix\": target_matrix,\n",
    "        \"query_ids\": query_ids,\n",
    "        \"gallery_ids\": gallery_ids,\n",
    "        \"metadata\": {\n",
    "            \"num_queries\": num_queries,\n",
    "            \"num_gallery_sd258\": num_sd258_gallery,\n",
    "            \"num_gallery_ts1k\": len(gallery_ts1k_templates),\n",
    "            \"num_gallery_total\": num_gallery,\n",
    "            \"matches_found\": matches_found\n",
    "        }\n",
    "    }\n",
    "    with open(identification_results_path, \"wb\") as f:\n",
    "        pkl.dump(results, f)\n",
    "    print(f\"   Saved to: {identification_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CMC Curve (Cumulative Match Characteristic)\n",
    "\n",
    "Evaluate identification performance at different ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RANKS TO DISPLAY ==========\n",
    "# Define which ranks to show in results and annotations\n",
    "DISPLAY_RANKS = [1, 10, 20, 30, 100, 1000]\n",
    "# ========================================\n",
    "\n",
    "def compute_cmc(score_matrix, target_matrix, max_rank=20):\n",
    "    \"\"\"\n",
    "    Compute Cumulative Match Characteristic (CMC) curve.\n",
    "    \n",
    "    Args:\n",
    "        score_matrix: Score matrix [num_queries, num_gallery]\n",
    "        target_matrix: Ground truth matrix [num_queries, num_gallery]\n",
    "        max_rank: Maximum rank to compute\n",
    "        \n",
    "    Returns:\n",
    "        cmc: CMC values for ranks 1 to max_rank\n",
    "    \"\"\"\n",
    "    num_queries = score_matrix.shape[0]\n",
    "    \n",
    "    # Get sorted indices (highest scores first)\n",
    "    sorted_indices = np.argsort(score_matrix, axis=1)[:, ::-1]\n",
    "    \n",
    "    # Initialize CMC\n",
    "    cmc = np.zeros(max_rank)\n",
    "    \n",
    "    # For each rank\n",
    "    for rank in range(max_rank):\n",
    "        # Get top-(rank+1) predictions\n",
    "        top_k_indices = sorted_indices[:, :rank+1]\n",
    "        \n",
    "        # Check if any of top-k matches is genuine\n",
    "        correct = 0\n",
    "        for q_idx in range(num_queries):\n",
    "            top_k = top_k_indices[q_idx]\n",
    "            if np.any(target_matrix[q_idx, top_k]):\n",
    "                correct += 1\n",
    "        \n",
    "        cmc[rank] = correct / num_queries\n",
    "    \n",
    "    return cmc\n",
    "\n",
    "# Compute CMC\n",
    "print(\"Computing CMC curve...\")\n",
    "cmc = compute_cmc(scores_matrix, target_matrix, max_rank=MAX_CMC_RANK)\n",
    "\n",
    "# Print key metrics for configured ranks\n",
    "print(f\"\\nðŸ“ˆ Identification Results:\")\n",
    "for rank in DISPLAY_RANKS:\n",
    "    if rank <= len(cmc):\n",
    "        print(f\"   Rank-{rank:<3}: {cmc[rank-1]*100:.2f}%\")\n",
    "\n",
    "# Plot CMC curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "ranks = np.arange(1, len(cmc) + 1)\n",
    "plt.plot(ranks, cmc * 100, 'b-', linewidth=2, label='DMD++ with Background Gallery')\n",
    "plt.xlabel('Rank', fontsize=12)\n",
    "plt.ylabel('Identification Rate (%)', fontsize=12)\n",
    "plt.title(f'CMC Curve - Gallery: {len(gallery_sd258_templates)} SD258 + {len(gallery_ts1k_templates)} TS1K', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xlim([1, len(cmc)])\n",
    "plt.ylim([0, 105])\n",
    "\n",
    "# Set x-axis ticks\n",
    "if len(cmc) <= 100:\n",
    "    plt.xticks(np.arange(0, len(cmc) + 1, 10))\n",
    "else:\n",
    "    plt.xticks(np.arange(0, len(cmc) + 1, 25))\n",
    "\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "# Add value annotations for configured ranks\n",
    "for rank in DISPLAY_RANKS:\n",
    "    rank_idx = rank - 1  # Convert to 0-indexed\n",
    "    if rank_idx < len(cmc):\n",
    "        plt.annotate(f'{cmc[rank_idx]*100:.1f}%', \n",
    "                    xy=(rank, cmc[rank_idx] * 100),\n",
    "                    xytext=(10, -10), textcoords='offset points',\n",
    "                    fontsize=9, color='darkblue',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='darkblue'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… CMC curve plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Case Analysis\n",
    "\n",
    "Visualize cases where Rank-1 prediction was incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get gallery image by index\n",
    "def get_gallery_image(idx):\n",
    "    \"\"\"Get gallery image by index (handles both SD258 and TS1K).\"\"\"\n",
    "    if idx < len(gallery_sd258):\n",
    "        return gallery_sd258[idx][\"orig\"]\n",
    "    else:\n",
    "        ts1k_idx = idx - len(gallery_sd258)\n",
    "        return gallery_ts1k[ts1k_idx][\"orig\"]\n",
    "\n",
    "def get_gallery_id(idx):\n",
    "    \"\"\"Get gallery external ID by index (handles both SD258 and TS1K).\"\"\"\n",
    "    if idx < len(gallery_sd258):\n",
    "        return f\"SD258: {noext(gallery_sd258[idx].external_id)}\"\n",
    "    else:\n",
    "        ts1k_idx = idx - len(gallery_sd258)\n",
    "        return f\"TS1K: {noext(gallery_ts1k[ts1k_idx].external_id)}\"\n",
    "\n",
    "MAX_DISPLAY_ERR = 30\n",
    "\n",
    "# Find error cases (where Rank-1 prediction is incorrect)\n",
    "sorted_indices = np.argsort(scores_matrix, axis=1)[:, ::-1]\n",
    "error_cases = []\n",
    "\n",
    "for q_idx in range(len(query_templates)):\n",
    "    # Get Rank-1 prediction\n",
    "    rank1_idx = sorted_indices[q_idx, 0]\n",
    "    \n",
    "    # Check if Rank-1 is correct\n",
    "    if not target_matrix[q_idx, rank1_idx]:\n",
    "        # Find the correct match (should be at q_idx in SD258 gallery)\n",
    "        correct_idx = np.where(target_matrix[q_idx])[0][0]\n",
    "        \n",
    "        # Find rank of correct match\n",
    "        correct_rank = np.where(sorted_indices[q_idx] == correct_idx)[0][0] + 1\n",
    "        \n",
    "        error_cases.append({\n",
    "            'query_idx': q_idx,\n",
    "            'predicted_idx': rank1_idx,\n",
    "            'correct_idx': correct_idx,\n",
    "            'predicted_score': scores_matrix[q_idx, rank1_idx],\n",
    "            'correct_score': scores_matrix[q_idx, correct_idx],\n",
    "            'correct_rank': correct_rank\n",
    "        })\n",
    "\n",
    "print(f\"ðŸ”´ Found {len(error_cases)} error cases (Rank-1 incorrect)\")\n",
    "print(f\"   Error rate: {len(error_cases)/len(query_templates)*100:.2f}%\")\n",
    "print(f\"   Displaying first {min(MAX_DISPLAY_ERR, len(error_cases))} cases\\n\")\n",
    "\n",
    "# Display error cases\n",
    "for i, err in enumerate(error_cases[:MAX_DISPLAY_ERR]):\n",
    "    q_idx = err['query_idx']\n",
    "    pred_idx = err['predicted_idx']\n",
    "    correct_idx = err['correct_idx']\n",
    "    \n",
    "    # Get images\n",
    "    query_img = queries[q_idx][\"orig\"]\n",
    "    predicted_img = get_gallery_image(pred_idx)\n",
    "    correct_img = get_gallery_image(correct_idx)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(query_img, cmap='gray')\n",
    "    axes[0].set_title(f'Query #{q_idx}\\n{noext(queries[q_idx].external_id)}', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(predicted_img, cmap='gray')\n",
    "    axes[1].set_title(f'Predicted (Rank-1) #{pred_idx}\\n{get_gallery_id(pred_idx)}\\nScore: {err[\"predicted_score\"]:.4f}', \n",
    "                     fontsize=11, color='red', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(correct_img, cmap='gray')\n",
    "    axes[2].set_title(f'Correct Match (Rank-{err[\"correct_rank\"]}) #{correct_idx}\\n{get_gallery_id(correct_idx)}\\nScore: {err[\"correct_score\"]:.4f}', \n",
    "                     fontsize=11, color='green', fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Error case {i+1}/{min(MAX_DISPLAY_ERR, len(error_cases))}: Query {q_idx} â†’ Predicted {pred_idx} (should be {correct_idx} at rank {err['correct_rank']})\")\n",
    "    print(f\"  Predicted score: {err['predicted_score']:.4f} | Correct score: {err['correct_score']:.4f}\\n\")\n",
    "\n",
    "print(\"\\nâœ… Error analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
